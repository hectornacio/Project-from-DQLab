{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58bc072",
   "metadata": {},
   "source": [
    "Mentor: Karl Christian (Business Intelligence at Traveloka)\n",
    "\n",
    "# DESKRIPSI\n",
    "Project ini adalah salah satu project yang terdapat di DQLab dan merupakan bagian dari proses pembelajaran saya di platform DQLab. DQLab adalah salah satu platform kursus data science di Indonesia.\n",
    "\n",
    "# Chapter 1\n",
    "## Introduction\n",
    "Membuat sebuah sistem rekomendasi berdasarkan konten dari sebuah film. \n",
    "### Pengenalan Project\n",
    "Masih ingat dengan project Building Recommender System using Python?\n",
    "\n",
    "Pada bagian sebelumnya kita telah melihat bagaimana recommender system dibuat hanya dengan menggunakan average rating, dengan mengurutkan score yang terdapat komponen average rating secara descending, kita dapat mengetahui (secara estimasi) film mana yang menurut para audience paling menarik.\n",
    "\n",
    "Kali ini, kita akan membuat recommender system yang menggunakan Content/feature dari film/entitas tersebut, kemudian melakukan perhitungan terhadap kesamaannya satu dan yang lain sehingga ketika kita menunjuk ke satu film, kita akan mendapat beberapa film lain yang memiliki kesamaan dengan film tersebut. Hal ini biasa kita sebut sebagai Content Based Recommender System.\n",
    "\n",
    "Dengan membandingkan kesamaan plot yang ada dan genre yang ada, ketika audience lebih menyukai film Narnia, maka content based recommender system ini akan juga merekomendasikan film seperti Harry Potter atau The Lords of The Rings yang memiliki genre yang mirip\n",
    "\n",
    "# Chapter 2\n",
    "## Task 1 - Unloading and Checking Datasets\n",
    "### Import Basics Library and File Unloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#lakukan pembacaan dataset\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv ') #untuk menyimpan movie_rating_df.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bf270",
   "metadata": {},
   "source": [
    "### Menampilkan 5 data teratas dan info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a8615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "#tampilkan 5 baris teratas dari movive_rating_df\n",
    "print(movie_rating_df.head())\n",
    "\n",
    "#tampilkan info mengenai tipe data dari tiap kolom\n",
    "print(movie_rating_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732f6f0",
   "metadata": {},
   "source": [
    "### Add Actors Dataframe\n",
    "Akses dataset: https://storage.googleapis.com/dqlab-dataset/actor_name.csv\n",
    "\n",
    "### Add Directors and Writers Dataframe\n",
    "Akses dataset : https://storage.googleapis.com/dqlab-dataset/directors_writers.csv\n",
    "\n",
    "### Convert into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22914d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "\n",
    "#Mengubah director_name menjadi list\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "#Tampilkan 5 data teratas\n",
    "print(director_writers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a492c",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "## Task 2 - Cleaning and Processing Table Cast\n",
    "### Update name_df\n",
    "Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles pada name_df untuk mencocokkan aktor/aktris ini dengan film yang ada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "#Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "#Tampilkan 5 baris teratas dari name_df\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9cdf5",
   "metadata": {},
   "source": [
    "### Movies per Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50343e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "#Melakukan pengecekan variasi\n",
    "print(name_df['knownForTitles'].apply(lambda x: len(x.split(','))).unique())\n",
    "\n",
    "#Mengubah knownForTitles menjadi list of list\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "#Mencetak 5 baris teratas\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e542d83",
   "metadata": {},
   "source": [
    "### Korespondensi 1 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1fb89c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (1895725559.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    df1.index = idx\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for x in ['knownForTitles']:\n",
    "    #mengulang index dari tiap baris sampai tiap elemen dari knownForTitles\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "   \n",
    "   #memecah values dari list di setiap baris dan menggabungkan nya dengan rows lain menjadi dataframe\n",
    "    df1 = pd.DataFrame({\n",
    "\t\tx: np.concatenate(name_df[x].values)\n",
    "\t})\n",
    "\n",
    "\t#mengganti index dataframe tersebut dengan idx yang sudah kita define di awal\n",
    "\tdf1.index = idx\n",
    "\n",
    "\t#untuk setiap dataframe yang terbentuk, kita menambahkan ke dataframe bucket\n",
    "\tdf_uni.append(df1)\n",
    "\n",
    "#menggabungkan semua dataframe menjadi satu\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "\n",
    "#join dengan value dari dataframe yang awal\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "\n",
    "#select kolom sesuai dengan dataframe awal\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "print(unnested_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946a126",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "## Task 3 - Nesting primaryName group by knownForTitles\n",
    "### Mengelompokkan primaryName menjadi list group by knownForTitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2865792",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     knownForTitles           cast_name\n",
      "0         tt0008125    [Charles Harley]\n",
      "1         tt0009706    [Charles Harley]\n",
      "2         tt0010304  [Natalie Talmadge]\n",
      "3         tt0011414  [Natalie Talmadge]\n",
      "4         tt0011890  [Natalie Talmadge]\n",
      "...             ...                 ...\n",
      "1893      tt9610496  [Stefano Baffetti]\n",
      "1894      tt9714030        [Kevin Kain]\n",
      "1895      tt9741820   [Caroline Plyler]\n",
      "1896      tt9759814     [Ethan Francis]\n",
      "1897      tt9856236     [Nuala Maguire]\n",
      "\n",
      "[1898 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ika N\\AppData\\Local\\Temp\\ipykernel_10684\\3581096920.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for col in ['primaryName']:\n",
    "    #agregasi kolom PrimaryName sesuai group_col yang sudah di define di atas\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    #Lakukan append\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576da9f",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "## Task 4 - Joining with Movie Table\n",
    "### Join table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f700f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "#join antara movie table dan cast table \n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "\n",
    "#join antara base_df dengan director_writer table\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "print(base_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d23272",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "#Melakukan drop terhadap kolom knownForTitles\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "print(base_drop.info())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom genres dengan 'Unknown'\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "\n",
    "#Melakukan perhitungan jumlah nilai NULL pada tiap kolom\n",
    "print(base_drop.isnull().sum())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom dorector_name dan writer_name dengan 'Unknown'\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "\n",
    "#karena value kolom genres terdapat multiple values, jadi kita akan bungkus menjadi list of list\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e4d0d",
   "metadata": {},
   "source": [
    "### Reformat table base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99572c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "#Drop kolom tconst, isAdult, endYear, originalTitle\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "\n",
    "# Gunakan petunjuk!\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "print(base_drop2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47bdb4b",
   "metadata": {},
   "source": [
    "# Chapter 6\n",
    "## Task 5 - Creating Content-based Recommender System\n",
    "### Klasifikasi Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "#Klasifikasi berdasar title, cast_name, genres, director_name, dan writer_name\n",
    "feature_df = base_drop2[['title', 'cast_name', 'genres', 'director_name', 'writer_name']]\n",
    "\n",
    "#Tampilkan 5 baris teratas\n",
    "print(feature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861339e",
   "metadata": {},
   "source": [
    "### Pertanyaan 1: Bagaimana cara membuat fungsi untuk strip spaces dari setiap row dan setiap elemennya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6536e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        #kalau cell berisi list\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        #kalau cell berisi string\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "        \n",
    "#Kolom : cast_name, genres, writer_name, director_name        \n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "#Apply function sanitize \n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d62993",
   "metadata": {},
   "source": [
    "### Pertanyaan 2: Bagaimana cara membuat fungsi untuk membuat metadata soup (menggabungkan semua feature menjadi 1 bagian kalimat) untuk setiap judulnya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "#kolom yang digunakan : cast_name, genres, director_name, writer_name\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "#membuat soup menjadi 1 kolom \n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abcf50",
   "metadata": {},
   "source": [
    "### Pertanyaan 3: Cara menyiapkan CountVectorizer (stop_words = english) dan fit dengan soup yang kita buat di atas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eee68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "#import CountVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#definisikan CountVectorizer dan mengubah soup tadi menjadi bentuk vector\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "print(count)\n",
    "print(count_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5b061",
   "metadata": {},
   "source": [
    "### Pertanyaan 4: Cara membuat model similarity antara count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "#Import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Gunakan cosine_similarity antara count_matrix \n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "#print hasilnya\n",
    "print(cosine_sim) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed2881",
   "metadata": {},
   "source": [
    "### Pertanyaan 5: Cara membuat content based recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd642d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "indices = pd.Series(feature_df.index, index=feature_df['title']).drop_duplicates()\n",
    "\n",
    "def content_recommender(title):\n",
    "    #mendapatkan index dari judul film (title) yang disebutkan\n",
    "    idx = indices[title]\n",
    "\n",
    "    #menjadikan list dari array similarity cosine sim \n",
    "    #hint: cosine_sim[idx]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #mengurutkan film dari similarity tertinggi ke terendah\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #untuk mendapatkan list judul dari item kedua sampe ke 11\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    #mendapatkan index dari judul-judul yang muncul di sim_scores\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #dengan menggunakan iloc, kita bisa panggil balik berdasarkan index dari movie_indices\n",
    "    return base_df.iloc[movie_indices]\n",
    "\n",
    "#aplikasikan function di atas\n",
    "print(content_recommender('The Lion King'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e16ce2",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "Tentang saya, silakan kunjungi: \n",
    "- rpubs: https://rpubs.com/ikanurfitriani/\n",
    "- github: https://github.com/ikanurfitriani\n",
    "- linkedin: https://linkedin.com/in/ikanurfitriani\n",
    "- medium: https://medium.com/@ikanurfitriani"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
